<!doctype html><html lang=en dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='今年很幸運有機會參加 NVIDIA AI Summit，參觀現場展示的最新 NVIDIA AI 技術，並聆聽 11 場精彩的演講。內容豐富又精實，讓人對 AI 的未來充滿熱血沸騰的期待，確切呼應了本次會議的大標語 -- 「探索 AI 時代的無限可能」。'><title>2024 NVIDIA AI SUMMIT 紀錄 - LLM 與 RAG 應用</title>
<link rel=canonical href=https://andreashih.com/blog/p/2024-nvidia-ai-summit-%E7%B4%80%E9%8C%84-llm-%E8%88%87-rag-%E6%87%89%E7%94%A8/><link rel=stylesheet href=/blog/scss/style.min.3c956c0cbbfaf45f38f6dbd671a1e8b8ee27736da20ead937f3845916c8b970a.css><meta property='og:title' content='2024 NVIDIA AI SUMMIT 紀錄 - LLM 與 RAG 應用'><meta property='og:description' content='今年很幸運有機會參加 NVIDIA AI Summit，參觀現場展示的最新 NVIDIA AI 技術，並聆聽 11 場精彩的演講。內容豐富又精實，讓人對 AI 的未來充滿熱血沸騰的期待，確切呼應了本次會議的大標語 -- 「探索 AI 時代的無限可能」。'><meta property='og:url' content='https://andreashih.com/blog/p/2024-nvidia-ai-summit-%E7%B4%80%E9%8C%84-llm-%E8%88%87-rag-%E6%87%89%E7%94%A8/'><meta property='og:site_name' content='The Andrea Journal'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='talks'><meta property='article:published_time' content='2024-06-06T00:00:00+00:00'><meta property='article:modified_time' content='2024-06-06T00:00:00+00:00'><meta property='og:image' content='https://andreashih.com/blog/p/2024-nvidia-ai-summit-%E7%B4%80%E9%8C%84-llm-%E8%88%87-rag-%E6%87%89%E7%94%A8/ai-summit-2.jpg'><meta name=twitter:title content="2024 NVIDIA AI SUMMIT 紀錄 - LLM 與 RAG 應用"><meta name=twitter:description content="今年很幸運有機會參加 NVIDIA AI Summit，參觀現場展示的最新 NVIDIA AI 技術，並聆聽 11 場精彩的演講。內容豐富又精實，讓人對 AI 的未來充滿熱血沸騰的期待，確切呼應了本次會議的大標語 -- 「探索 AI 時代的無限可能」。"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content='https://andreashih.com/blog/p/2024-nvidia-ai-summit-%E7%B4%80%E9%8C%84-llm-%E8%88%87-rag-%E6%87%89%E7%94%A8/ai-summit-2.jpg'><link rel="shortcut icon" href=/fav.png><script async src="https://www.googletagmanager.com/gtag/js?id=G-ZSM78MJWQ9"></script><script>var dnt,doNotTrack=!1;if(!1&&(dnt=navigator.doNotTrack||window.doNotTrack||navigator.msDoNotTrack,doNotTrack=dnt=="1"||dnt=="yes"),!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-ZSM78MJWQ9")}</script></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/blog/><img src=/blog/img/bio-photo_huea51e07d5fb1e8f04a22f8a210f49255_619524_300x0_resize_q75_box.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>🌸</span></figure><div class=site-meta><h1 class=site-name><a href=/blog>The Andrea Journal</a></h1><h2 class=site-description>Think, write, and think again 💭</h2></div></header><ol class=social-menu><li><a href=https://andreashih.com target=_blank title="back to profile"><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-arrow-back" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M9 11l-4 4 4 4m-4-4h11a4 4 0 000-8h-1"/></svg></a></li><li><a href=https://github.com/andreashih target=_blank title=github><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li><li><a href=https://andreashih.github.io/blog/index.xml target=_blank title=rss><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-rss" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="5" cy="19" r="1"/><path d="M4 4a16 16 0 0116 16"/><path d="M4 11a9 9 0 019 9"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/blog/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/blog/_index.zh-cn/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>主页</span></a></li><li><a href=/blog/about/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-user" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="7" r="4"/><path d="M6 21v-2a4 4 0 014-4h4a4 4 0 014 4v2"/></svg>
<span>About</span></a></li><li><a href=/blog/archives/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/blog/search/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><div class=menu-bottom-section><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg>
<select name=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://andreashih.com/blog/ selected>English</option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></div></ol></aside><main class="main full-width"><article class="has-image main-article"><header class=article-header><div class=article-image><a href=/blog/p/2024-nvidia-ai-summit-%E7%B4%80%E9%8C%84-llm-%E8%88%87-rag-%E6%87%89%E7%94%A8/><img src=/blog/p/2024-nvidia-ai-summit-%E7%B4%80%E9%8C%84-llm-%E8%88%87-rag-%E6%87%89%E7%94%A8/ai-summit-2_hu3b59245f2f3da6eaf09149d5eb1f54b9_259638_800x0_resize_q75_box.jpg srcset="/blog/p/2024-nvidia-ai-summit-%E7%B4%80%E9%8C%84-llm-%E8%88%87-rag-%E6%87%89%E7%94%A8/ai-summit-2_hu3b59245f2f3da6eaf09149d5eb1f54b9_259638_800x0_resize_q75_box.jpg 800w, /blog/p/2024-nvidia-ai-summit-%E7%B4%80%E9%8C%84-llm-%E8%88%87-rag-%E6%87%89%E7%94%A8/ai-summit-2_hu3b59245f2f3da6eaf09149d5eb1f54b9_259638_1600x0_resize_q75_box.jpg 1600w" width=800 height=600 loading=lazy alt="Featured image of post 2024 NVIDIA AI SUMMIT 紀錄 - LLM 與 RAG 應用"></a></div><div class=article-details><header class=article-category><a href=/blog/categories/working/ style=background-color:;color:#fff>working</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/blog/p/2024-nvidia-ai-summit-%E7%B4%80%E9%8C%84-llm-%E8%88%87-rag-%E6%87%89%E7%94%A8/>2024 NVIDIA AI SUMMIT 紀錄 - LLM 與 RAG 應用</a></h2><h3 class=article-subtitle>今年很幸運有機會參加 NVIDIA AI Summit，參觀現場展示的最新 NVIDIA AI 技術，並聆聽 11 場精彩的演講。內容豐富又精實，讓人對 AI 的未來充滿熱血沸騰的期待，確切呼應了本次會議的大標語 -- 「探索 AI 時代的無限可能」。</h3></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Jun 06, 2024</time></div></footer></div></header><section class=article-content><h2 id=dli-示範課程建立-gpu-加速的檢索增強生成-rag-流程>DLI 示範課程：建立 GPU 加速的檢索增強生成 (RAG) 流程</h2><p><em><strong>杜承翰</strong>, 資深解決方案架構師, NVIDIA</em></p><figure><img src=/blog/p/2024-nvidia-ai-summit-%E7%B4%80%E9%8C%84-llm-%E8%88%87-rag-%E6%87%89%E7%94%A8/rag/rag.jpg width=70% height=auto><figcaption><h4>RAG Sequence Diagram (source: https://blogs.nvidia.com.tw/blog/what-is-retrieval-augmented-generation/)</h4></figcaption></figure><p>講師介紹了檢索增強生成 (RAG) 的框架，並透過 <a class=link href=https://python.langchain.com/v0.2/docs/integrations/providers/nvidia/ target=_blank rel=noopener>LangChain</a> 程式碼進行實作，介紹如何建立一個完整的 RAG 流程。<code>langchain-nvidia-ai-endpoints</code> 整合了 LangChain 功能，可使用 NVIDIA NIM 微服務上的模型建構 applications。</p><p>RAG 的流程包括：</p><ol><li>資料預處理</li><li>索引與檢索</li><li>透過 LLM 生成結果</li></ol><h3 id=llm-的限制>LLM 的限制</h3><p>LLM 雖然強大，但可能存在以下限制：</p><ul><li>過時的訓練資料</li><li>特定領域知識不足</li><li>幻覺</li><li>偏差資訊</li></ul><h3 id=rag-提高-llm-可靠性>RAG 提高 LLM 可靠性</h3><p><a class=link href=https://blogs.nvidia.com.tw/blog/what-is-retrieval-augmented-generation/ target=_blank rel=noopener>檢索增強生成 (RAG)</a> 是一種技術/過程，透過使用外部資料來提高生成式 AI 模型的準確性和可靠性。在企業應用範疇中，將 LLM 連接到企業資料，可以生成最新的特定領域答案。其優勢包括：</p><ul><li>與企業資料的交流</li><li>保護資料隱私</li><li>減輕 LLM 的幻覺</li><li>讓 LLM 優先使用相關資訊，無需重新訓練或微調模型</li></ul><h3 id=nvidia-nemo>NVIDIA NEMO</h3><p>RAG 生態系統非常複雜，企業必須整合、更新和維護開源解決方案。使用 <a class=link href=https://developer.nvidia.com/nemo-microservices target=_blank rel=noopener>NVIDIA NeMo</a>
可以最佳化 RAG 應用程式。</p><figure><img src=/blog/p/2024-nvidia-ai-summit-%E7%B4%80%E9%8C%84-llm-%E8%88%87-rag-%E6%87%89%E7%94%A8/rag/nemo.webp width=70% height=auto><figcaption><h4>NeMo Framework (source: https://docs.nvidia.com/nemo-framework/index.html)</h4></figcaption></figure><h3 id=評估-rag-系統>評估 RAG 系統</h3><p>建造出服務後，往往會碰到一個問題：如何評估模型好壞。講者介紹了以下兩種 RAG 評估方式，判斷生成結果的相關性和正確性。</p><ul><li><a class=link href=https://www.trulens.org/ target=_blank rel=noopener>TruLens</a>: TruLens 提供 TruRails 工具，與 <a class=link href=https://github.com/NVIDIA/NeMo-Guardrails target=_blank rel=noopener>NeMo Guardrails</a> 應用程式整合，可用於評估生成結果。</li><li><a class=link href=https://github.com/explodinggradients/ragas target=_blank rel=noopener>RAGAS</a>: RAGAS 可以使用 LangChain 來連接 NVIDIA AI foundation model 和 endpoint 進行評估。</li></ul><p>📖 <strong>延伸閱讀</strong>：<a class=link href=https://medium.com/@ajaimlianzy/rag-toolbox-methodologies-for-evaluating-rag-systems-f95ed4b90bdc target=_blank rel=noopener>TruLens, RAGAS 與其他評估方法</a></p><h2 id=理解專利請求項附屬關係的自動生成模型>理解專利請求項附屬關係的自動生成模型</h2><p><em><strong>陳豐奇</strong>, 副所長, 國家衛生研究院</em></p><p>在 IPR (Inter Partes Review) 的過程中，專利會經過多方複審，涉及到案件、法官、當事人等。這些實體關係近似於 social network，可以用 Entity Relation 表徵。</p><p>專利請求項包括獨立項和附屬項，每一項都必須是單一完整的句子。附屬項越多，專利保護範圍越小。以下列例子說明：</p><blockquote><ol><li><strong>A</strong> device comprising an operating face of a front face of the device&mldr; (獨立項)</li><li><strong>The</strong> device according to claim 1&mldr; (附屬項)</li><li><strong>The</strong> device according to claim 2&mldr; (附屬項)</li></ol></blockquote><p>第一點是獨立項，第二和第三點是附屬項。</p><p>專利包含結構附屬 (structural dependency) 和技術附屬 (technical dependency) ，兩者都正確編寫才能形成有效的附屬項。LLM能否做到這一點呢？</p><p>由於專利數據無法上傳至雲端，使用地端 LLM 進行微調變得尤其重要。研究中使用了不同的開源 LLM 進行微調，並評估生成的專利請求項內文。其中一項評估方法是讓三位專利工程師進行盲測，人工驗證結果。結果顯示，地端微調的 LLM 得分幾乎與 GPT-4 相當。即使是較小的模型，經過微調後也能達到與大型 LLM 相同的效果，生成出具有正確寫作風格的專利請求項。</p><h2 id=如何透過整合文化背景來改進大型語言模型建模>如何透過整合文化背景來改進大型語言模型建模</h2><p><em><strong>陳縕儂</strong>, 副教授, 國立台灣大學</em></p><p><a class=link href=https://github.com/MiuLab/Taiwan-LLM target=_blank rel=noopener>Taiwan-LLM</a> 的訓練方法旨在使模型本地化，結合台灣的文化背景，並加強繁體中文的支援，提升其在地應用效果。</p><h3 id=台灣本土資料上進行持續預訓練>台灣本土資料上進行持續預訓練</h3><p>TAME (TAiwan Mixture of Experts) 計劃網羅各領域專家，蒐集來自媒體、法律、醫療、化工、製造業和遊戲等多個領域的本土資料。</p><ul><li>Model: Llama-3 8B & 70B</li><li>Context Length: 8192</li><li>Long Context Extension: 64k</li><li>Training Framework: Nvidia NeMo, Nvidia NeMo Megatron</li><li>Inference Framework: Nvidia TensorRT-LLM</li><li>Hardware: Nvidia DGX H100 on Taipei-1</li><li>Training Stack: 3D parallelism, DeepSpeed Zero, Flash Attention 降低記憶體用量並加速訓練</li></ul><h3 id=生成多輪-ai-對話資料進行微調>生成多輪 AI 對話資料進行微調</h3><p>在<a class=link href=http://arena.twllm.com/ target=_blank rel=noopener>繁體中文 LLM 競技場</a>蒐集真實使用者的回饋，以進行模型微調。</p><h3 id=真實使用者互動並微調>真實使用者互動並微調</h3><p>透過 <a class=link href=https://arxiv.org/abs/2305.18290 target=_blank rel=noopener>Direct Preference Optimization</a> (DPO) 方法，根據使用者的偏好計算 maximum likelihood，最終微調 LLM。</p><h3 id=llm-評估>LLM 評估</h3><p><a class=link href=https://huggingface.co/spaces/yentinglin/open-tw-llm-leaderboard target=_blank rel=noopener>Open Taiwan LLM Leaderboard</a> 展示了各模型在不同任務上的表現。評估測試集包含：</p><ul><li>TMLU: 衡量模型理解各個領域 (國中、高中、大學、國考) 的能力。</li><li>TW Truthful QA: 評估模型以臺灣特定背景回答問題的能力。</li><li>TW Legal Eval: 評估模型對臺灣法律術語和概念的理解。</li><li>MMLU: 測試模型在英語各種任務上的表現。</li></ul><h2 id=探討繁中大型語言模型建構之挑戰與克服>探討繁中大型語言模型建構之挑戰與克服</h2><p><em><strong>陳宜昌</strong>, 聯發創新基地</em><br><em><strong>許大山</strong>, 創新基地負責人, 聯發科技</em></p><p>聯發科與 NVIDIA 持續合作，<a class=link href=https://huggingface.co/MediaTek-Research/Breeze-7B-Instruct-v0_1 target=_blank rel=noopener>Breeze-7B</a> 和 <a class=link href=https://huggingface.co/MediaTek-Research/Breexe-8x7B-Instruct-v0_1 target=_blank rel=noopener>BreeXe-8x7B</a> 已上架 NVIDIA Inference Microservice (NIM) 。Breeze 模型在訓練中僅使用 2 台 H100，其性能已接近於使用 10 倍算力的 Llama3。</p><h3 id=挑戰與克服>挑戰與克服</h3><ol><li><p>缺乏 benchmark<br>MediaTek Research 發布了 <a class=link href=https://huggingface.co/datasets/MediaTek-Research/TCEval-v2 target=_blank rel=noopener>TC-Eval</a> 繁體中文 LLM benchmark，提供一個全面的評估標準。</p></li><li><p>缺乏大規模的預訓練數據<br><a class=link href=https://commoncrawl.org/ target=_blank rel=noopener>Common Crawl</a> 是一個龐大的公開網絡爬蟲數據集，截至 2023 年 12 月，數據量達到 454 TB。但繁體中文的資料還是非常少。</p><ul><li>英文：44%</li><li>簡體中文：5%</li><li>繁體中文：0.1%<br>MediaTek Research 通過多種方法收集了 1 TB 的臺灣繁體中文數據。</li></ul></li><li><p>開源模型中支援的繁中 vocabularies 也非常少：</p><ul><li>LLaMA2: 563 out of 32k</li><li>Mistral: 1034 out of 32k<br>MediaTek Research 開發了技術，將繁體中文的 vocabularies 擴展到超過 32k。</li></ul></li></ol><h3 id=breeze-7b>Breeze-7B</h3><ul><li>免費開源</li><li>Source Model: Mistral 7B</li><li>繁體中文 vocabulary size 提升到 62k<ul><li>Inference 速度提高 2%</li><li>繁中 context length 達到 11.1k，相當於 10 頁文本</li></ul></li><li>使用總計 7,000 小時 H100 預訓練 650 GB 的資料</li></ul><h3 id=breexe-8x7b>BreeXe-8x7B</h3><ul><li>Source Model: Mistral 8x7B (混合專家模型，<a class=link href=https://huggingface.co/blog/moe target=_blank rel=noopener>Mixture of Experts</a>, MoE)</li><li>繁體中文 vocabulary size 提升到 62k</li><li>BreeXe 的對話能力與 GPT3.5 相當</li><li>BreeXe 在台灣知識方面優於 GPT3.5</li></ul><h3 id=breezper>Breezper</h3><p>使用 <a class=link href=https://arxiv.org/abs/2405.14259 target=_blank rel=noopener>Generative Fusion Decoding</a> (GFD) 技術，以 Breeze-7B + Whisper 打造語音模型。</p><ul><li>提升同音字辨識率</li><li>提升 code switching 辨識率</li><li>實現 contextual-aware ASR</li></ul><h2 id=鴻海-genai-戰略>鴻海 GenAI 戰略</h2><p><em><strong>栗永徽</strong>, 所長, 鴻海研究院</em></p><p>鴻海 AI 戰略全力投入基礎模型技術，目標打造全方位解決方案平台。憑藉鴻海集團即將建置的龐大算力，人工智慧研究所將為集團研發 FoxBrain，作為三大平台底層最重要的智慧核心。三大平台為：</p><ol><li>Smart Manufacturing 智慧製造</li><li>Smart EVs 智慧電動車</li><li>Smart City 智慧城市</li></ol><h3 id=基礎模型細節>基礎模型細節</h3><ul><li>輕量高效的 LLM：實現更快的運算速度和更低的能耗。</li><li>人類偏好對齊：確保模型能夠對齊人類偏好，並設置 model guardrail 以防止不當生成。</li><li>多模態能力：增強模型在多種模態下的表現能力，包括視覺和語音的綜合應用。</li></ul><h3 id=foxbrain-目標>FoxBrain 目標</h3><ul><li>多模態 AI 代理人<ul><li>視覺-語言 (VLM)</li><li>自駕助手 (CabinGPT)</li><li>音頻-視覺-語言 (FoxBot 機器人)</li></ul></li><li>特定領域 AI 專家模型<ul><li>智慧醫療</li><li>智慧辦公室</li><li>智慧工廠</li><li>智慧城市</li></ul></li></ul><h3 id=訓練過程透過-nvidia-工具優化>訓練過程透過 NVIDIA 工具優化</h3><ol><li>數據構建階段：<a class=link href=https://github.com/NVIDIA/NeMo-Curator target=_blank rel=noopener>NVIDIA NeMo Curator</a></li></ol><ul><li>自動化清理、轉換和分析數據</li><li>透過優化算法提升處理速度</li></ul><ol start=2><li>模型訓練階段：<a class=link href=https://github.com/NVIDIA/NeMo-Framework-Launcher target=_blank rel=noopener>NVIDIA NeMo Megatron</a></li></ol><ul><li>在高品質數據上繼續預訓練</li><li>在各種下游 NLP 任務上進行微調</li></ul><ol start=3><li>模型部署階段：<a class=link href=https://www.nvidia.com/zh-tw/ai-data-science/products/triton-inference-server/ target=_blank rel=noopener>NVIDIA Triton 推論服務器</a></li></ol><ul><li>優化 neural network 以加快執行速度</li><li>低延遲，提升性能</li></ul></section><footer class=article-footer><section class=article-tags><a href=/blog/tags/talks/>Talks</a></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article class=has-image><a href=/blog/p/2024-nvidia-ai-summit-%E7%B4%80%E9%8C%84-%E6%99%BA%E6%85%A7%E8%A3%BD%E9%80%A0%E8%88%87%E5%85%B6%E4%BB%96/><div class=article-image><img src=/blog/p/2024-nvidia-ai-summit-%E7%B4%80%E9%8C%84-%E6%99%BA%E6%85%A7%E8%A3%BD%E9%80%A0%E8%88%87%E5%85%B6%E4%BB%96/ai-summit.361072f0ab564067a14b87d2921639df_hu863ab52b023c1d3676337ffd66b6297c_277338_250x150_fill_q75_box_smart1.jpg width=250 height=150 loading=lazy alt="Featured image of post 2024 NVIDIA AI SUMMIT 紀錄 - 智慧製造與其他" data-hash="md5-NhBy8KtWQGehS4fSkhY53w=="></div><div class=article-details><h2 class=article-title>2024 NVIDIA AI SUMMIT 紀錄 - 智慧製造與其他</h2></div></a></article><article class=has-image><a href=/blog/p/%E5%8F%B0%E9%81%94%E9%9B%BB%E5%AD%90%E5%AF%A6%E7%BF%92%E5%BF%83%E5%BE%97-%E5%BE%8C%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%AB-backend-engineer/><div class=article-image><img src=/blog/p/%E5%8F%B0%E9%81%94%E9%9B%BB%E5%AD%90%E5%AF%A6%E7%BF%92%E5%BF%83%E5%BE%97-%E5%BE%8C%E7%AB%AF%E5%B7%A5%E7%A8%8B%E5%B8%AB-backend-engineer/computer.7f43a861dd3b4057432725a3e3cb356c_hu4174250a65c1d336799b339fc25686ca_82201_250x150_fill_q75_box_smart1.jpg width=250 height=150 loading=lazy alt="Featured image of post 台達電子實習心得 - 後端工程師 (Backend Engineer)" data-hash="md5-f0OoYd07QFdDJyWj48s1bA=="></div><div class=article-details><h2 class=article-title>台達電子實習心得 - 後端工程師 (Backend Engineer)</h2></div></a></article></div></div></aside><div class=disqus-container><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//theandreajournal.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2024 The Andrea Journal</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.13.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#dli-示範課程建立-gpu-加速的檢索增強生成-rag-流程>DLI 示範課程：建立 GPU 加速的檢索增強生成 (RAG) 流程</a><ol><li><a href=#llm-的限制>LLM 的限制</a></li><li><a href=#rag-提高-llm-可靠性>RAG 提高 LLM 可靠性</a></li><li><a href=#nvidia-nemo>NVIDIA NEMO</a></li><li><a href=#評估-rag-系統>評估 RAG 系統</a></li></ol></li><li><a href=#理解專利請求項附屬關係的自動生成模型>理解專利請求項附屬關係的自動生成模型</a></li><li><a href=#如何透過整合文化背景來改進大型語言模型建模>如何透過整合文化背景來改進大型語言模型建模</a><ol><li><a href=#台灣本土資料上進行持續預訓練>台灣本土資料上進行持續預訓練</a></li><li><a href=#生成多輪-ai-對話資料進行微調>生成多輪 AI 對話資料進行微調</a></li><li><a href=#真實使用者互動並微調>真實使用者互動並微調</a></li><li><a href=#llm-評估>LLM 評估</a></li></ol></li><li><a href=#探討繁中大型語言模型建構之挑戰與克服>探討繁中大型語言模型建構之挑戰與克服</a><ol><li><a href=#挑戰與克服>挑戰與克服</a></li><li><a href=#breeze-7b>Breeze-7B</a></li><li><a href=#breexe-8x7b>BreeXe-8x7B</a></li><li><a href=#breezper>Breezper</a></li></ol></li><li><a href=#鴻海-genai-戰略>鴻海 GenAI 戰略</a><ol><li><a href=#基礎模型細節>基礎模型細節</a></li><li><a href=#foxbrain-目標>FoxBrain 目標</a></li><li><a href=#訓練過程透過-nvidia-工具優化>訓練過程透過 NVIDIA 工具優化</a></li></ol></li></ol></nav></div></section></aside></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/blog/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>